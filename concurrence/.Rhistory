demo()
library(ggplot2)
1+2+3+4
library(RCurl)
#1. Charger les packages
library(httr)
library(XML)
#2. Récupérer le code source
url <- "https://remibacha.com"
request <- GET(url)
doc <- htmlParse(request, asText = TRUE)
#3. Récupérer le title et compter le nombre de caractères
PageTitle <- xpathSApply(doc, "//title", xmlValue)
nchar(PageTitle)
#4. Récupérer les noms des articles
PostTitles <- data.frame(xpathSApply(doc, "//h2[@class='entry-title h1']", xmlValue))
PostTitles <- data.frame(xpathSApply(doc, "//h2", xmlValue))
#5. Récupérer tous les liens de la page et en faire une liste
hrefs <- xpathSApply(doc, "//div/a", xmlGetAttr, 'href')
hrefs <- data.frame(matrix(unlist(hrefs), byrow=T))
#6. Récupérer les liens du menu
liensmenu <- xpathSApply(doc, "//ul[@id='menu-menu']//a", xmlGetAttr, 'href')
liensmenu <- data.frame(matrix(unlist(liensmenu), byrow=T))
#7. Récupérer le status code et le header
status_code(request)
header <- headers(request)
header <- data.frame(matrix(unlist(header), byrow=T))
library(ggplot2)
install.packages("Rcpp")
library(ggplot2)
getwd()
setwd('/home/goach/Documents/workspace/R_Folder/concurrence/')
install.packages('devtools')
devtools::create('concurrence_ecocup')
devtools::create('concurrence-ecocup')
devtools::create('concurrence.ecocup')
