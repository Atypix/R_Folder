demo()
library(ggplot2)
1+2+3+4
library(RCurl)
#1. Charger les packages
library(httr)
library(XML)
#2. Récupérer le code source
url <- "https://remibacha.com"
request <- GET(url)
doc <- htmlParse(request, asText = TRUE)
#3. Récupérer le title et compter le nombre de caractères
PageTitle <- xpathSApply(doc, "//title", xmlValue)
nchar(PageTitle)
#4. Récupérer les noms des articles
PostTitles <- data.frame(xpathSApply(doc, "//h2[@class='entry-title h1']", xmlValue))
PostTitles <- data.frame(xpathSApply(doc, "//h2", xmlValue))
#5. Récupérer tous les liens de la page et en faire une liste
hrefs <- xpathSApply(doc, "//div/a", xmlGetAttr, 'href')
hrefs <- data.frame(matrix(unlist(hrefs), byrow=T))
#6. Récupérer les liens du menu
liensmenu <- xpathSApply(doc, "//ul[@id='menu-menu']//a", xmlGetAttr, 'href')
liensmenu <- data.frame(matrix(unlist(liensmenu), byrow=T))
#7. Récupérer le status code et le header
status_code(request)
header <- headers(request)
header <- data.frame(matrix(unlist(header), byrow=T))
library(ggplot2)
install.packages("Rcpp")
library(ggplot2)
install.packages("devtools")
install_github('plotly/dashR', upgrade = TRUE)
install.packages("dashHtmlComponents")
install.packages("dashCoreComponents")
install.packages("dashTable")
install.packages("dashTable", repo = "https://mac.R-project.org")
install.packages('dashTable',repos='http://cran.us.r-project.org')
install.packages("dash")
setwd('/home/goach/Documents/workspace/R_Folder/ecocup-analytics/analytics/imports')
source('import.R')
setwd('/home/goach/Documents/workspace/R_Folder/ecocup-analytics/analytics/')
source('analytics.R')
